{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import sklearn as sk\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model.logistic import LogisticRegression\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rouge = [[1,4], [2,3], [3,2], [4,1], [2,4], [3,3], [4,2] ]\n",
    "bleu = [[1,2], [2,1], [3,0], [4,-1], [1,1], [2,0], [2,-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter([x for x,y in rouge], [y for x,y in rouge], color='red')\n",
    "plt.scatter([x for x,y in bleu], [y for x,y in bleu], color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous pouvons indiquer l'hyperplane séparateur (ci-bas).\n",
    "\n",
    "* à discuter : pourquoi y a-t-il un point mal-classifié?  (La réponse est bêtement facile mais assez difficile à trouver la première fois.  N'hésitez pas à discuter sur slack.)\n",
    "* jouez avec les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Inspired by https://stackoverflow.com/questions/20045994/how-do-i-plot-the-decision-boundary-of-a-regression-using-matplotlib\n",
    "# and http://stackoverflow.com/questions/28256058/plotting-decision-boundary-of-logistic-regression\n",
    "\n",
    "X = np.array(rouge + bleu)\n",
    "y = [1] * len(rouge) + [0] * len(bleu)\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X, y)\n",
    "\n",
    "xx, yy = np.mgrid[0:5:.01, -2:5:.01]\n",
    "grid = np.c_[xx.ravel(), yy.ravel()]\n",
    "probs = logreg.predict_proba(grid)[:, 1].reshape(xx.shape)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.contour(xx, yy, probs, levels=[.5], cmap=\"Greys\", vmin=0, vmax=.6)\n",
    "\n",
    "plt.scatter([x for x,y in rouge], [y for x,y in rouge], color='red')\n",
    "plt.scatter([x for x,y in bleu], [y for x,y in bleu], color='blue')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Un exemple plus approfondi\n",
    "\n",
    "Exercices\n",
    "* Jouez avec le code pour comprendre la forme de chaque variable.\n",
    "* Découvrez le sens de \"target\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Code source: Gaël Varoquaux\n",
    "# Modified for documentation by Jaques Grobler\n",
    "# License: BSD 3 clause\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, datasets\n",
    "\n",
    "# Import some data to play with.\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "Y = iris.target\n",
    "\n",
    "h = .02  # step size in the mesh\n",
    "\n",
    "logreg = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "# We create an instance of Neighbours Classifier and fit the data.\n",
    "logreg.fit(X, Y)\n",
    "\n",
    "# Plot the decision boundary. For that, we will assign a color to each\n",
    "# point in the mesh [x_min, m_max]x[y_min, y_max].\n",
    "x_min, x_max = X[:, 0].min() - .5, X[:, 0].max() + .5\n",
    "y_min, y_max = X[:, 1].min() - .5, X[:, 1].max() + .5\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "Z = logreg.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "\n",
    "# Put the result into a color plot.\n",
    "Z = Z.reshape(xx.shape)\n",
    "plt.figure(1, figsize=(4, 3))\n",
    "plt.pcolormesh(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "\n",
    "# Plot also the training points.\n",
    "plt.scatter(X[:, 0], X[:, 1], c=Y, edgecolors='k', cmap=plt.cm.Paired)\n",
    "plt.xlabel('Sepal length')\n",
    "plt.ylabel('Sepal width')\n",
    "\n",
    "plt.xlim(xx.min(), xx.max())\n",
    "plt.ylim(yy.min(), yy.max())\n",
    "plt.xticks(())\n",
    "plt.yticks(())\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Détection de spam avec la régression logistique\n",
    "\n",
    "Il aurait fallu télécharger le corpus de spam [ici](http://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection), puis l'unzipper dans le répertoire `spam-corpus`.  Mais ici c'est déjà fait."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('spam-corpus/SMSSpamCollection', delimiter='\\t', header=None)\n",
    "print(df.head())\n",
    "print('\\n')\n",
    "print('Number of spam messages: {n}'.format(n=df[df[0] == 'spam'][0].count()))\n",
    "print('Number of ham messages: {n}'.format(n=df[df[0] == 'ham'][0].count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il nous faut d'abord des critères (features).  Puis nous allons utiliser TF-IDF pour trouver les mots les plus représentatifs des sms spam et ham.\n",
    "\n",
    "* Explorez les training data et test data, cru et cuit.\n",
    "* Pourquoi disons-nous `fit_transform()` pour les _training data_, mais `transform()` pour les _test data_?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "X_train_raw, X_test_raw, y_train, y_test = train_test_split(df[1], df[0])\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(X_train_raw)\n",
    "X_test = vectorizer.transform(X_test_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enfin, nous créeons un classifieur par régression logistique.  Comme tout classifieur en scikit-learn, il nous propose `fit()` et `predict()`.  Il faut toujours visualiser nos données et nos résultats, ce que nous faisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "predictions = classifier.predict(X_test)\n",
    "num_to_show = 5\n",
    "for msg, prediction in zip(X_test_raw[:num_to_show], predictions[:num_to_show]):\n",
    "    print('Prediction: {pred}.\\nMessage: {msg}\\n'.format(\n",
    "           pred=prediction, msg=msg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Métriques de performance\n",
    "\n",
    "OK, nous avons classifié les messages, mais avec quel taux de précision?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "yy_test = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n",
    "yy_pred = [0, 1, 0, 0, 0, 0, 0, 1, 1, 1]\n",
    "confusion = confusion_matrix(yy_test, yy_pred)\n",
    "print(confusion)\n",
    "plt.matshow(confusion)\n",
    "plt.title('Confusion matrix')\n",
    "plt.gray()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()\n",
    "\n",
    "# Ou si on voudrait que le noir nous montre les plus communs :\n",
    "invert_colors = np.ones(confusion.shape) * confusion.max()\n",
    "plt.matshow(invert_colors - confusion)\n",
    "plt.title('Confusion matrix')\n",
    "plt.gray()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice\n",
    "\n",
    "* Qu'est-ce qui est la matrice de confusion pour notre classifieur de spam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good_scores = cross_val_score(classifier, X_train, y_train, cv=5)\n",
    "random_X_train = np.random.rand(X_train.shape[0], X_train.shape[1])\n",
    "bad_scores = cross_val_score(classifier, random_X_train, y_train, cv=5)\n",
    "print('good', good_scores)\n",
    "print('bad', bad_scores)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
